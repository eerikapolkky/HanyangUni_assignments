{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2bb886cedba24eae9d8a0d6116d1d9d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d1e28c08cf724865a483d70ccc1ba4f2",
              "IPY_MODEL_37e5d97786e44b96b9c72434e340ba76",
              "IPY_MODEL_74585f6d02c8433cb173291e40738f41"
            ],
            "layout": "IPY_MODEL_028c86f471684db2a985daaba694fd1f"
          }
        },
        "d1e28c08cf724865a483d70ccc1ba4f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a1a5ac793ed409ba4920dbe772508b3",
            "placeholder": "​",
            "style": "IPY_MODEL_9f8dced568c745b0a77ce9ff5eeee9ee",
            "value": "  2%"
          }
        },
        "37e5d97786e44b96b9c72434e340ba76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2433b0b060ec42da9afaf32bc99dbdf8",
            "max": 3000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aa4c76efc2834e2da7e3cf52ee1fbcec",
            "value": 49
          }
        },
        "74585f6d02c8433cb173291e40738f41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6652db833a7436dbcd3c1cb631b94a7",
            "placeholder": "​",
            "style": "IPY_MODEL_389d3ea198444ceb9498eed8fb69e04b",
            "value": " 49/3000 [07:59&lt;9:26:11, 11.51s/it]"
          }
        },
        "028c86f471684db2a985daaba694fd1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a1a5ac793ed409ba4920dbe772508b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f8dced568c745b0a77ce9ff5eeee9ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2433b0b060ec42da9afaf32bc99dbdf8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa4c76efc2834e2da7e3cf52ee1fbcec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e6652db833a7436dbcd3c1cb631b94a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "389d3ea198444ceb9498eed8fb69e04b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate sacrebleu\n",
        "\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
        "import evaluate\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "GzaFfANs1neq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab5b207c-1b05-4eda-db61-413fedf239af"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.12/dist-packages (0.4.6)\n",
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.12/dist-packages (2.5.1)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.0.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.0.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate) (3.6.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.36.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from evaluate) (25.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (3.2.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (2025.11.3)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (6.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (3.20.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (6.0.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.13.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2025.11.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_datasets = load_dataset(\"wmt14\", \"de-en\")\n",
        "print(raw_datasets)\n",
        "print(raw_datasets[\"train\"][0])"
      ],
      "metadata": {
        "id": "xKpVQTfA1pYs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dee1df8f-c85c-40f4-c91a-818cb481033f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['translation'],\n",
            "        num_rows: 4508785\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['translation'],\n",
            "        num_rows: 3000\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['translation'],\n",
            "        num_rows: 3003\n",
            "    })\n",
            "})\n",
            "{'translation': {'de': 'Wiederaufnahme der Sitzungsperiode', 'en': 'Resumption of the session'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"facebook/mbart-large-50-many-to-many-mmt\"\n",
        "\n",
        "tokenizer = MBart50TokenizerFast.from_pretrained(model_name)\n",
        "model = MBartForConditionalGeneration.from_pretrained(model_name).to(device)\n",
        "\n",
        "src_lang = \"en_XX\"\n",
        "tgt_lang = \"de_DE\"\n",
        "\n",
        "tokenizer.src_lang = src_lang\n",
        "model.config.forced_bos_token_id = tokenizer.lang_code_to_id[tgt_lang]\n",
        "\n",
        "print(\"Model and tokenizer ready\")\n"
      ],
      "metadata": {
        "id": "tq1bBosL1rRn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91694de0-0db7-49ad-b370-8cc1d30750ed"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model and tokenizer ready\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, hf_split, tokenizer, max_length=128):\n",
        "        self.data = hf_split\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        example = self.data[idx]\n",
        "        src_text = example[\"translation\"][\"en\"]\n",
        "        tgt_text = example[\"translation\"][\"de\"]\n",
        "\n",
        "        model_inputs = self.tokenizer(\n",
        "            src_text,\n",
        "            max_length=self.max_length,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "\n",
        "        with self.tokenizer.as_target_tokenizer():\n",
        "            labels = self.tokenizer(\n",
        "                tgt_text,\n",
        "                max_length=self.max_length,\n",
        "                truncation=True,\n",
        "                padding=\"max_length\",\n",
        "                return_tensors=\"pt\",\n",
        "            )\n",
        "\n",
        "        item = {\n",
        "            \"input_ids\": model_inputs[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": model_inputs[\"attention_mask\"].squeeze(0),\n",
        "            \"labels\": labels[\"input_ids\"].squeeze(0),\n",
        "        }\n",
        "        return item\n",
        "\n",
        "max_length = 128\n",
        "\n",
        "train_dataset = TranslationDataset(raw_datasets[\"train\"], tokenizer, max_length)\n",
        "val_dataset   = TranslationDataset(raw_datasets[\"validation\"], tokenizer, max_length)\n",
        "test_dataset  = TranslationDataset(raw_datasets[\"test\"], tokenizer, max_length)\n"
      ],
      "metadata": {
        "id": "rLwF9ea_1t8_"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sacrebleu\n",
        "import numpy as np\n",
        "\n",
        "bleu = evaluate.load(\"sacrebleu\")\n",
        "\n",
        "def postprocess_text(preds, labels):\n",
        "    preds = [p.strip() for p in preds]\n",
        "    labels = [[l.strip()] for l in labels]\n",
        "    return preds, labels\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
        "\n",
        "    result = bleu.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "    return {\"bleu\": result[\"score\"]}"
      ],
      "metadata": {
        "id": "F5I1SMFK17rp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd67d3a7-94ba-4ece-a61c-e6463f4ad8c9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.12/dist-packages (2.5.1)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (3.2.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (2025.11.3)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (2.0.2)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (6.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "batch_size = 4\n",
        "num_epochs = 3\n",
        "learning_rate = 3e-5\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./mbart-en-de\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=learning_rate,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=num_epochs,\n",
        "    weight_decay=0.01,\n",
        "    predict_with_generate=True,\n",
        "    logging_steps=100,\n",
        "    save_strategy=\"no\",\n",
        ")\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "'''"
      ],
      "metadata": {
        "collapsed": true,
        "id": "CDpH9XCi19cX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "063fa8aa-7d8b-4135-f9f7-fed29a265f5a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nbatch_size = 4\\nnum_epochs = 3\\nlearning_rate = 3e-5\\n\\ntraining_args = Seq2SeqTrainingArguments(\\n    output_dir=\"./mbart-en-de\",\\n    evaluation_strategy=\"epoch\",\\n    learning_rate=learning_rate,\\n    per_device_train_batch_size=batch_size,\\n    per_device_eval_batch_size=batch_size,\\n    num_train_epochs=num_epochs,\\n    weight_decay=0.01,\\n    predict_with_generate=True,\\n    logging_steps=100,\\n    save_strategy=\"no\",\\n)\\n\\ndata_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\\n\\ntrainer = Seq2SeqTrainer(\\n    model=model,\\n    args=training_args,\\n    train_dataset=train_dataset,\\n    eval_dataset=val_dataset,\\n    tokenizer=tokenizer,\\n    data_collator=data_collator,\\n    compute_metrics=compute_metrics,\\n)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tuning\n",
        "# trainer.train()\n",
        "\n",
        "# Evaluation on test set\n",
        "# results = trainer.evaluate(test_dataset)\n",
        "# print(\"Test BLEU:\", results[\"eval_bleu\"])\n"
      ],
      "metadata": {
        "id": "axfqRLbF2DDf"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "preds = []\n",
        "refs = []\n",
        "\n",
        "# for example in raw_datasets[\"test\"]:\n",
        "#     src_text = example[\"translation\"][\"en\"]\n",
        "#     tgt_text = example[\"translation\"][\"de\"]\n",
        "#     ...\n",
        "\n",
        "# (bleu.compute(...) as shown earlier)\n"
      ],
      "metadata": {
        "id": "MWAP7Zwk2FKw"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
        "\n",
        "model_name = \"facebook/mbart-large-50-many-to-many-mmt\"\n",
        "\n",
        "tokenizer = MBart50TokenizerFast.from_pretrained(model_name)\n",
        "model = MBartForConditionalGeneration.from_pretrained(model_name).to(device)\n",
        "\n",
        "src_lang = \"en_XX\"\n",
        "tgt_lang = \"de_DE\"\n",
        "\n",
        "tokenizer.src_lang = src_lang\n",
        "model.config.forced_bos_token_id = tokenizer.lang_code_to_id[tgt_lang]\n",
        "\n",
        "print(\"Model reloaded successfully.\")\n"
      ],
      "metadata": {
        "id": "n0C8rQEbQkih",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edb080d5-061f-4e72-903e-ecc6d5cd9670"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model reloaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_sentence(sentence_en):\n",
        "    model.eval()\n",
        "    inputs = tokenizer(\n",
        "        sentence_en,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        max_length=128,\n",
        "        padding=True\n",
        "    ).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        generated_ids = model.generate(\n",
        "            **inputs,\n",
        "            max_length=128,\n",
        "            num_beams=4,\n",
        "            early_stopping=True\n",
        "        )\n",
        "\n",
        "    return tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
        "\n",
        "example = \"This is a sentence for testing and I might say something more complicated to test you.\"\n",
        "print(\"English:\", example)\n",
        "print(\"German:\", translate_sentence(example))\n",
        "\n"
      ],
      "metadata": {
        "id": "QG26GQnn2Mtt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c9176ab-4fc7-455b-8ced-9d0e860ab961"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English: This is a sentence for testing and I might say something more complicated to test you.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py:1733: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed in v5. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "German: Dies ist ein Satz zum Testen und ich könnte etwas komplizierteres sagen, um Sie zu testen.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "example = raw_datasets[\"test\"][0][\"translation\"][\"en\"]\n",
        "print(\"English:\", example)\n",
        "# print(\"German (ref):\", raw_datasets[\"test\"][0][\"translation\"][\"de\"])\n",
        "# print(\"German (model):\", translate_sentence(example))\n",
        "'''"
      ],
      "metadata": {
        "id": "LK6EsYdz2Pn9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "fa5abcfb-b6da-4f80-8022-788bb5d993bf"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nexample = raw_datasets[\"test\"][0][\"translation\"][\"en\"]\\nprint(\"English:\", example)\\n# print(\"German (ref):\", raw_datasets[\"test\"][0][\"translation\"][\"de\"])\\n# print(\"German (model):\", translate_sentence(example))\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bleu = evaluate.load(\"sacrebleu\")\n",
        "\n",
        "model.eval()\n",
        "preds = []\n",
        "refs = []\n",
        "\n",
        "n_eval = 50\n",
        "\n",
        "for i, example in enumerate(tqdm(raw_datasets[\"validation\"])):\n",
        "    src = example[\"translation\"][\"en\"]\n",
        "    tgt = example[\"translation\"][\"de\"]\n",
        "\n",
        "    inputs = tokenizer(\n",
        "        src,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        max_length=128,\n",
        "        padding=True,\n",
        "    ).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        generated = model.generate(\n",
        "            **inputs,\n",
        "            max_length=128,\n",
        "            num_beams=4,\n",
        "            early_stopping=True,\n",
        "        )\n",
        "\n",
        "    pred = tokenizer.decode(generated[0], skip_special_tokens=True)\n",
        "    preds.append(pred)\n",
        "    refs.append([tgt])\n",
        "\n",
        "    if i + 1 >= n_eval:\n",
        "        break\n",
        "\n",
        "result = bleu.compute(predictions=preds, references=refs)\n",
        "print(\"Validation BLEU:\", result[\"score\"])\n"
      ],
      "metadata": {
        "id": "eGvxznZNXEY2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "2bb886cedba24eae9d8a0d6116d1d9d6",
            "d1e28c08cf724865a483d70ccc1ba4f2",
            "37e5d97786e44b96b9c72434e340ba76",
            "74585f6d02c8433cb173291e40738f41",
            "028c86f471684db2a985daaba694fd1f",
            "5a1a5ac793ed409ba4920dbe772508b3",
            "9f8dced568c745b0a77ce9ff5eeee9ee",
            "2433b0b060ec42da9afaf32bc99dbdf8",
            "aa4c76efc2834e2da7e3cf52ee1fbcec",
            "e6652db833a7436dbcd3c1cb631b94a7",
            "389d3ea198444ceb9498eed8fb69e04b"
          ]
        },
        "outputId": "004cec23-7510-4da7-b805-9865425e088a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2bb886cedba24eae9d8a0d6116d1d9d6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation BLEU: 27.66010717166846\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used the pretrained mBART50 model for English→German translation together with the WMT14 dataset.\n",
        "I implemented a simple translation pipeline and calculated BLEU on a small subset of the validation set,\n",
        "because running the full sequence generation on CPU-only Colab would be too slow. The BLEU score on this subset was above 0.10, showing that the translation setup works correctly.\n"
      ],
      "metadata": {
        "id": "J2nAL5k4q0cK"
      }
    }
  ]
}